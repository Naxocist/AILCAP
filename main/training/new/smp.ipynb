{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.11 (you have 1.4.10). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import albumentations as A\n",
    "from tifffile import imread\n",
    "from random import randint, shuffle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import segmentation_models as sm\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "\t\"\"\"PLot images in one row.\"\"\"\n",
    "\tn = len(images)\n",
    "\tplt.figure(figsize=(16, 5))\n",
    "\tfor i, (name, image) in enumerate(images.items()):\n",
    "\t\tplt.subplot(1, n, i + 1)\n",
    "\t\tplt.xticks([])\n",
    "\t\tplt.yticks([])\n",
    "\t\tplt.title(' '.join(name.split('_')).title())\n",
    "\t\tplt.imshow(image)\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\tundefined (0)\n",
    "\tlepidic (1)\n",
    "\tacinar (2)\n",
    "\tmicropapillary (3)\n",
    "\tpapillary (4)\n",
    "\tsolid (5)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "\tdef __init__(\n",
    "\t\t\tself, \n",
    "\t\t\troot,\n",
    "\t\t\taugmentation=None, \n",
    "\t\t\tpreprocessing=None,\n",
    "\t\t):\n",
    "\t\tself.classes = ['background', 'lepidic', 'acinar', 'micropapillary', 'papillary', 'solid']\n",
    "\n",
    "\n",
    "\t\tself.images_path = glob.glob(str(root / \"images/*\"))\n",
    "\t\tself.masks_path = glob.glob(str(root / \"masks/*\"))\n",
    "\n",
    "\t\tprint(self.images_path)\n",
    "\t\tprint(self.masks_path)\n",
    "  \n",
    "\t\t# collecting sample for every class\n",
    "\t\tto_collect = [0, 10, 10, 10, 10, 10]\n",
    "\t\tself.images_test_path = []\n",
    "\t\tself.masks_test_path = []\n",
    "\n",
    "\t\tdef collect_sample(img_p, msk_p):\n",
    "\t\t\tmask = np.asarray(imread(msk_p), dtype=np.uint8)\n",
    "\n",
    "\t\t\tc = np.unique(self.to_index(mask))[-1]\n",
    "\n",
    "\t\t\tif to_collect[c] == 0: return \n",
    "\n",
    "\t\t\tto_collect[c] -= 1\n",
    "\n",
    "\t\t\tself.images_test_path.append(img_p)\n",
    "\t\t\tself.masks_test_path.append(msk_p)\n",
    "\n",
    "\t\t\tself.images_path.remove(img_p)\n",
    "\t\t\tself.masks_path.remove(msk_p)\n",
    "\n",
    "\t\t# multithread\n",
    "\t\tfutures = []\n",
    "\t\twith ThreadPoolExecutor(max_workers=8) as executor:\n",
    "\t\t\tfor img_p, msk_p in zip(self.images_path, self.masks_path):\n",
    "\t\t\t\tfutures.append(executor.submit(collect_sample, img_p, msk_p))\n",
    "\t\t\n",
    "\t\t\t# Wait for all futures to complete\n",
    "\t\t\tfor future in as_completed(futures):\n",
    "\t\t\t\tfuture.result()  # This will raise any exceptions that occurred\n",
    "\n",
    "\t\t\n",
    "\t\tprint(\"Collect state: \", to_collect)\n",
    "\n",
    "\t\tself.augmentation = augmentation\n",
    "\t\tself.preprocessing = preprocessing\n",
    "\n",
    "\n",
    "\tdef merge(self, x):\n",
    "\t\tdim = (x.shape[-2], x.shape[-1])\n",
    "\t\tmerged = np.zeros(dim)\n",
    "\t\tfor i in range(len(self.classes)):\n",
    "\t\t\tmerged = np.where(merged==0, x[i], merged)\n",
    "\n",
    "\t\tmerged  = merged.reshape(dim[0], dim[1], 1)\n",
    "\n",
    "\t\treturn merged\n",
    "\n",
    "\n",
    "\tdef to_index(self, x):\n",
    "\t\tfor c in range(len(self.classes)):\n",
    "\t\t\tx[c][x[c] == 255] = c \n",
    "\t\t\n",
    "\t\treturn x\n",
    "\n",
    "\n",
    "\tdef export_split(self, a, b, ratio = 0.5, cat = False):\n",
    "\t\t\n",
    "\t\tl_size = int(len(a) * ratio)\n",
    "\n",
    "\t\timages = np.asarray([imread(x) for x in a], dtype=np.uint8)\n",
    "\t\tmasks = np.asarray([self.merge(self.to_index(imread(x))) for x in b], dtype=np.uint8)\n",
    "\n",
    "\t\tprint(images.shape, masks.shape)\n",
    "\t\t\n",
    "\t\tif cat:\n",
    "\t\t\tmasks = to_categorical(masks, num_classes=len(self.classes))\n",
    "\n",
    "\t\tx_left = images[:l_size]\n",
    "\t\ty_left = masks[:l_size]\n",
    "\n",
    "\t\tx_right = images[l_size:]\n",
    "\t\ty_right = masks[l_size:]\n",
    "\n",
    "\t\treturn x_left, y_left, x_right, y_right\n",
    "\n",
    "\n",
    "\tdef __getitem__(self, i):\n",
    "\t\t\n",
    "\t\t# read data\n",
    "\t\timage = np.asarray(imread(self.images_path[i]), dtype=np.uint8)\n",
    "\t\tmask = np.asarray(imread(self.masks_path[i]), dtype=np.uint8)\n",
    "\n",
    "\t\tmask = self.to_index(mask)\n",
    "\t\tmask = self.merge(mask)\n",
    "\n",
    "\t\t# apply augmentations\n",
    "\t\tif self.augmentation:\n",
    "\t\t\tsample = self.augmentation(image=image, mask=mask)\n",
    "\t\t\timage, mask = sample['image'], sample['mask']\n",
    "\t\t\n",
    "\t\t# apply preprocessing\n",
    "\t\tif self.preprocessing:\n",
    "\t\t\tsample = self.preprocessing(image=image, mask=mask)\n",
    "\t\t\timage, mask = sample['image'], sample['mask']\n",
    "\t\t\t\n",
    "\t\treturn image, mask\n",
    "\t\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 512px*512px of 1x downsampled images\n",
    "SIZE = 512\n",
    "root = Path(r'D:\\NSC2024\\annotated\\merged\\1')\n",
    "\n",
    "dataset = Dataset(root=root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of dataset: \", len(dataset))\n",
    "r = randint(0, len(dataset) - 1)\n",
    "image, masks = dataset[r]\n",
    "\n",
    "print(\"Mask unique: \", np.unique(masks))\n",
    "print(\"Mask shape: \", masks.shape)\n",
    "visualize(\n",
    "\timage=image,\n",
    "\tmask=masks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.export_split(dataset.images_path[:10], dataset.masks_path[:10], ratio=0.5, cat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model():\n",
    "\tdef __init__(self, arch, backbone, encoder, lr, activation):\n",
    "\t\tself.arch = arch\n",
    "\t\tself.backbone = backbone\n",
    "\n",
    "\t\t# callbacks\n",
    "\t\tself.checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "\t\t\tf'./models/{arch}/{backbone}/best_model.keras',\n",
    "\t\t\tmonitor='iou_score',\n",
    "\t\t\tverbose=1,\n",
    "\t\t\tsave_best_only=True,\n",
    "\t\t\tsave_weights_only=False,\n",
    "\t\t\tmode='max',\n",
    "\t\t\tsave_freq='epoch',\n",
    "\t\t\tinitial_value_threshold=None\n",
    "\t\t)\n",
    "\t\tname = arch + \"-\" + backbone\n",
    "\t\tself.tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f\"logs/{name}\")\n",
    "\t\t\n",
    "\t\t# loss functions\n",
    "\t\tdice_loss = sm.losses.DiceLoss(class_weights=np.array([0, .2, .2, .2, .2, .2])) \n",
    "\t\tfocal_loss = sm.losses.CategoricalFocalLoss()\n",
    "\t\tjaccard_loss = sm.losses.JaccardLoss()\n",
    "\t\ttotal_loss = dice_loss + (1 * focal_loss) \n",
    "\n",
    "\t\t# metrices\n",
    "\t\tmetrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "\t\tself.preprocess = sm.get_preprocessing(backbone)\n",
    "\n",
    "\t\topt = keras.optimizers.Adam(lr)\n",
    "\n",
    "\t\tif arch == \"Unet\":\n",
    "\t\t\tself.model = sm.Unet(backbone_name=backbone, encoder_weights=encoder, activation=activation, classes=6, input_shape=(SIZE, SIZE, 3))\n",
    "\t\t\tself.model.compile(opt, total_loss, metrics=metrics)\n",
    "\t\telse:\n",
    "\t\t\tprint(\"Unknown model arch. The model is undefined.\")\n",
    "\t\n",
    "\n",
    "\tdef summary(self):\n",
    "\t\tself.model.summary()\n",
    "\n",
    "\n",
    "\tdef train(self):\n",
    "\t\tSET_SIZE = 100\n",
    "\t\tcnt = 1\n",
    "\n",
    "\t\tbatch_size = 16\n",
    "\n",
    "\t\tepoch_step = 10\n",
    "\t\tinitial_epoch = 0\n",
    "\n",
    "\t\tgoal = len(dataset)\n",
    "\t\tfor i in tqdm(range(0, goal, SET_SIZE)):\n",
    "\t\t\tx_train, y_train, x_val, y_val = dataset.export_split(dataset.images_path[i:i+SET_SIZE], dataset.masks_path[i:i+SET_SIZE], ratio=0.7, cat=True)\n",
    "\n",
    "\t\t\tpre_x_train = self.preprocess(x_train)\n",
    "\t\t\tpre_x_val = self.preprocess(x_val)\n",
    "\n",
    "\t\t\thistory = self.model.fit(pre_x_train, y_train,\n",
    "\t\t\t\t\t\t\t\tvalidation_data=(pre_x_val, y_val),\n",
    "\t\t\t\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\t\t\t\tshuffle=True,\n",
    "\t\t\t\t\t\t\t\tverbose=1,\n",
    "\t\t\t\t\t\t\t\tinitial_epoch=initial_epoch,\n",
    "\t\t\t\t\t\t\t\tepochs=initial_epoch + epoch_step,\n",
    "\t\t\t\t\t\t\t\tcallbacks=[self.checkpoint, self.tensorboard]\n",
    "\t\t\t\t\t\t\t\t)\n",
    "\n",
    "\t\t\tself.model.save(f'./models/{self.arch}/{self.backbone}/latest_after_{initial_epoch + epoch_step}_epochs.keras')\n",
    "\n",
    "\t\t\tcnt += 1\n",
    "\t\t\tinitial_epoch += epoch_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model(arch=\"Unet\", backbone=\"resnet34\", encoder=\"imagenet\", activation=\"softmax\", lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('./models/Linknet/resnet34/latest_after_160_epochs.keras', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test, x_tmp, y_tmp = dataset.export_split(dataset.images_test_fps, dataset.masks_test_fps, 1, cat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_x_test = preprocess_input(x_test)\n",
    "y_pred = model.predict(pre_x_test)\n",
    "y_pred_argmax = np.argmax(y_pred, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred_argmax.shape)\n",
    "np.unique(y_pred_argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import MeanIoU\n",
    "\n",
    "IOU_keras = MeanIoU(num_classes=len(dataset.classes)+1)  \n",
    "IOU_keras.update_state(y_test, y_pred_argmax)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_to_rgb(x):\n",
    "\tx_reshaped = np.concatenate([x] * 3, axis=-1)\n",
    "\tcolor_map = {\n",
    "\t\t\t1: [255, 0, 0],   # Red for lepidic\n",
    "\t\t\t2: [0, 255, 0],   # Green for acinar\n",
    "\t\t\t3: [0, 0, 255],    # Blue for micropapillary\n",
    "\t\t\t4: [255, 255, 0],  # Yellow for papillary\n",
    "\t\t\t5: [255, 0, 255],   # violet for solid\n",
    "\t\t}\n",
    "\t\n",
    "\trgb = np.zeros_like(x_reshaped, dtype=np.uint8)\n",
    "\tfor label, color in color_map.items():\n",
    "\t\t\trgb[x_reshaped[..., 0] == label] = color \n",
    "\treturn rgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to colors according to classes\n",
    "y_test_show_rgb = gray_to_rgb(y_test)\n",
    "\n",
    "y_pred_argmax = np.expand_dims(y_pred_argmax, axis=-1)\n",
    "y_pred_argmax_show_rgb = gray_to_rgb(y_pred_argmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = randint(0, len(x_test)-1)\n",
    "# idx = 16\n",
    "print(y_test.shape)\n",
    "print(\"y_test unique: \", np.unique(y_test[idx]))\n",
    "print(\"y_pred_argmax unique: \", np.unique(y_pred_argmax[idx]))\n",
    "\n",
    "for idx in range(0, len(x_test)-1):\n",
    "\n",
    "\n",
    "\tvisualize(\n",
    "\t\timage=x_test[idx],\n",
    "\t\tground_truth=y_test_show_rgb[idx],\n",
    "\t\tpredict=y_pred_argmax_show_rgb[idx]\n",
    "\t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
