{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tifffile import imread\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import glob\n",
    "\n",
    "# Import PyTorch and matplotlib\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "# Check PyTorch version\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\tdef __init__(self, root) -> None:\n",
    "\t\tself.root = root\n",
    "\t\tself.transforms = transforms.Compose([\n",
    "\t\t\ttransforms.ToTensor(),\n",
    "\t\t])\n",
    "\n",
    "\t\tself.images_path = glob.glob(str(root / \"images/*\"))\n",
    "\t\tself.masks_path = glob.glob(str(root / \"masks/*\"))\n",
    "\t\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\timage = np.asarray(imread(self.images_path[index])) # H W C\n",
    "\t\tmask = np.asarray(imread(self.masks_path[index])) # C H W\n",
    "\n",
    "\t\tt_image = self.transforms(image) # C H W\n",
    "\t\tt_mask = torch.permute(self.transforms(mask), (1, 2, 0)) # C H W\n",
    "\n",
    "\t\treturn t_image, t_mask\n",
    "\t\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Path(\"E:/test_extract/export\")\n",
    "\n",
    "SIZE = 512\n",
    "\n",
    "data_path = base / str(SIZE)\n",
    "final_path = data_path / \"1\"\n",
    "\n",
    "# for i in os.walk(data_path):\n",
    "# \tpath, subpaths, items = i\n",
    "\n",
    "# \tprint(f\"{path} has {len(subpaths)} subpaths and {len(items)} items\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(root=final_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "r = randint(0, len(dataset)-1)\n",
    "\n",
    "image, mask = dataset[r]\n",
    "\n",
    "print(\"Image shape: \", image.shape)\n",
    "print(\"Mask shape: \", mask.shape, \" | \", \"Mask unique: \", np.unique(mask))\n",
    "\n",
    "visualize(\n",
    "    image=image,\n",
    "    mask_0 = mask[0],\n",
    "    mask_1 = mask[1],\n",
    "    mask_2 = mask[2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "dataloader = DataLoader(dataset=dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "images, masks = next(iter(dataloader))\n",
    "\n",
    "print(images.shape, masks.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in dataloader:\n",
    "    \n",
    "    print(image.shape, mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=3,                      # model output channels (number of classes in your dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-5\n",
    "included_classes = [0, 1, 2]\n",
    "\n",
    "jaccard = smp.losses.JaccardLoss(mode=\"multilabel\")\n",
    "\n",
    "diceloss = smp.losses.DiceLoss(mode=\"multilabel\", eps=eps, ignore_index=0)\n",
    "\n",
    "focalloss = smp.losses.FocalLoss(mode=\"multilabel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer \n",
    "optim = torch.optim.Adam(params=model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "from random import choice, randint\n",
    "with torch.inference_mode():\n",
    "    dataloader_list = list(dataloader)\n",
    "\n",
    "    random_batch = choice(dataloader_list)\n",
    "    random_index = randint(0, len(random_batch[0]) - 1)\n",
    "    image, mask = random_batch[0][random_index], random_batch[1][random_index]\n",
    "\n",
    "\n",
    "    image = image.unsqueeze(0)\n",
    "    mask = mask.unsqueeze(0)\n",
    "\n",
    "    print(image.shape, mask.shape)\n",
    "    y_pred = model(image)\n",
    "    print(y_pred.shape, np.unique(y_pred))\n",
    "\n",
    "    test = y_pred.detach().numpy().argmax(axis=1)\n",
    "    \n",
    "    print(\"TEST UNIQUE: \", np.unique(test))\n",
    "\n",
    "\n",
    "    visualize(\n",
    "        img=torch.permute(image[0], (1, 2, 0)),\n",
    "        a=y_pred[0][0],\n",
    "        b=y_pred[0][1],\n",
    "        c=y_pred[0][2],\n",
    "        A=mask[0][0],\n",
    "        B=mask[0][1],\n",
    "        C=mask[0][2],\n",
    "        test=test[0]\n",
    "    )\n",
    "\n",
    "    loss = jaccard(y_pred, mask)\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "\tfor epoch in range(epochs):\n",
    "\t\tmodel.train()\n",
    "\t\trunning_loss = 0\n",
    "\n",
    "\t\tfor image, y_true in tqdm(train_loader):\n",
    "\t\t\t# images.to(device)\n",
    "\t\t\t# masks.to(device)\n",
    "\n",
    "\t\t\timage = image.unsqueeze(0) # B C H W\n",
    "\t\t\ty_true = y_true.unsqueeze(0) # B C H W\n",
    "\t\t\tprint(f\"Image shape: {image.shape} | Mask shape: {y_true.shape}\")\n",
    "\n",
    "\t\t\ty_pred = model(image)\n",
    "\n",
    "\t\t\tprint(f\"Predicted shape: {y_pred.shape}\")\n",
    "\n",
    "\t\t\tloss = criterion(y_pred, y_true)\n",
    "\t\t\tprint(loss)\n",
    "\t\t\trunning_loss += loss\n",
    "\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\t\tloss.backward()\n",
    "\n",
    "\t\t\toptimizer.step()\n",
    "\n",
    "\t\t\t# model.eval()\n",
    "\n",
    "\n",
    "\t\tepoch_loss = running_loss / len(train_loader)\n",
    "\t\t\n",
    "\t\tprint(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, dataset, dataset, jaccard, optim, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
