{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'segmentation_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mA\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtifffile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m imread\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msegmentation_models\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m randint, shuffle\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'segmentation_models'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import albumentations as A\n",
    "from tifffile import imread\n",
    "import segmentation_models as sm\n",
    "from random import randint, shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            export_uri,\n",
    "            classes=None, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "            \n",
    "    ):\n",
    "        self.classes = classes\n",
    "\n",
    "\n",
    "        self.images_fps = []\n",
    "        self.masks_fps = []\n",
    "\n",
    "        # Loop through all downsamples\n",
    "        for downsample in os.listdir(export_uri):\n",
    "            for image_id in os.listdir(os.path.join(export_uri, downsample, 'images')):\n",
    "                self.images_fps.append(os.path.join(export_uri, downsample, 'images', image_id))\n",
    "\n",
    "            for mask_id in os.listdir(os.path.join(export_uri, downsample, 'masks')):\n",
    "                self.masks_fps.append(os.path.join(export_uri, downsample, 'masks', mask_id))\n",
    "\n",
    "        # Loop through downsample x1\n",
    "        # for image_id in os.listdir(os.path.join(export_uri, '1', 'images')):\n",
    "        #     self.images_fps.append(os.path.join(export_uri, '1', 'images', image_id))\n",
    "\n",
    "        # for mask_id in os.listdir(os.path.join(export_uri, '1', 'masks')):\n",
    "        #     self.masks_fps.append(os.path.join(export_uri, '1', 'masks', mask_id))\n",
    "\n",
    "        to_collect = [5, 5, 5, 5, 5]\n",
    "        self.images_test_fps = []\n",
    "        self.masks_test_fps = []\n",
    "\n",
    "        for image_path, mask_path in zip(self.images_fps, self.masks_fps):\n",
    "            mask = np.asarray(imread(mask_path), dtype=np.uint8)\n",
    "\n",
    "            un = np.unique(self.to_index(mask))[-1]\n",
    "            if to_collect[un - 1] == 0:\n",
    "                continue \n",
    "\n",
    "            to_collect[un - 1] -= 1\n",
    "            self.images_test_fps.append(image_path)\n",
    "            self.masks_test_fps.append(mask_path)\n",
    "\n",
    "            self.images_fps.remove(image_path)\n",
    "            self.masks_fps.remove(mask_path)\n",
    "\n",
    "            if all(x == 0 for x in to_collect):\n",
    "                break \n",
    "\n",
    "        # convert str names to class values on masks\n",
    "        self.class_values = [classes.index(cls.lower()) for cls in classes]\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "\n",
    "    def merge(self, x):\n",
    "        dim = (x.shape[-2], x.shape[-1])\n",
    "        merged = np.zeros(dim)\n",
    "        for i in range(len(self.classes)):\n",
    "            merged = np.where(merged==0, x[i], merged)\n",
    "\n",
    "        merged  = merged.reshape(dim[0], dim[1], 1)\n",
    "\n",
    "        return merged\n",
    "\n",
    "\n",
    "    def to_index(self, x):\n",
    "        for c in range(len(self.classes)):\n",
    "            x[c][x[c] == 255] = c + 1\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "    def export_split(self, a, b, ratio = 0.5, cat = False):\n",
    "        \n",
    "        l_size = int(len(a) * ratio)\n",
    "\n",
    "        images = []\n",
    "        for image_uri in a:\n",
    "            img = np.asarray(imread(image_uri), dtype=np.uint8)\n",
    "            images.append(img)\n",
    "        \n",
    "        images = np.asarray(images)\n",
    "\n",
    "        masks = []\n",
    "        for mask_uri in b:\n",
    "            mask = np.asarray(imread(mask_uri), dtype=np.uint8)\n",
    "            mask = self.to_index(mask)\n",
    "            mask = self.merge(mask)\n",
    "            masks.append(mask)\n",
    "        \n",
    "        masks = np.asarray(masks)\n",
    "\n",
    "        print(images.shape, masks.shape)\n",
    "\n",
    "        if cat:\n",
    "            masks = to_categorical(masks, num_classes=len(self.classes) + 1)\n",
    "\n",
    "        x_left = images[:l_size]\n",
    "        y_left = masks[:l_size]\n",
    "\n",
    "        x_right = images[l_size:]\n",
    "        y_right = masks[l_size:]\n",
    "\n",
    "        return x_left, y_left, x_right, y_right\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = np.asarray(imread(self.images_fps[i]), dtype=np.uint8)\n",
    "        mask = np.asarray(imread(self.masks_fps[i]), dtype=np.uint8)\n",
    "\n",
    "        mask = self.to_index(mask)\n",
    "        mask = self.merge(mask)\n",
    "\n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOCUS ON 256px*256px images\n",
    "export_uri = r'D:\\NSC2024\\annotated\\jj\\export\\256'\n",
    "export_uri_2 = r'D:\\NSC2024\\annotated\\prxm\\export\\256'\n",
    "\n",
    "dataset = Dataset(\n",
    "    export_uri=export_uri,\n",
    "    classes = ['lepidic', 'acinar', 'micropapillary', 'papillary', 'solid'],\n",
    ")\n",
    "\n",
    "dataset2 = Dataset(\n",
    "    export_uri=export_uri_2,\n",
    "    classes = ['lepidic', 'acinar', 'micropapillary', 'papillary', 'solid'],\n",
    ")\n",
    "\n",
    "print(len(dataset), len(dataset2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = randint(0, len(dataset) - 1)\n",
    "image, masks = dataset[r]\n",
    "print(np.unique(masks))\n",
    "print(masks.shape)\n",
    "visualize(\n",
    "    image=image,\n",
    "    mask=masks\n",
    ")\n",
    "\n",
    "r = randint(0, len(dataset2) - 1)\n",
    "image, masks = dataset2[r]\n",
    "print(np.unique(masks))\n",
    "print(masks.shape)\n",
    "visualize(\n",
    "    image=image,\n",
    "    mask=masks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "BACKBONE = 'resnet34'\n",
    "activation='softmax'\n",
    "LR = 0.0001\n",
    "opt = keras.optimizers.Adam(LR)\n",
    "\n",
    "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
    "# set class weights for dice_loss (car: 1.; pedestrian: 2.; background: 0.5;)\n",
    "dice_loss = sm.losses.DiceLoss(class_weights=np.array([0.5, 0.20, 2., 0.20, 0.20, 0.20])) \n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "jaccard_loss = sm.losses.JaccardLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss) \n",
    "\n",
    "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
    "# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    './models/Linknet/resnet34/best_model.keras',\n",
    "    monitor='iou_score',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='max',\n",
    "    save_freq='epoch',\n",
    "    initial_value_threshold=None\n",
    ")\n",
    "\n",
    "Name = \"Linknet-\" + BACKBONE\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='logs/{}'.format(Name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = sm.Linknet(BACKBONE, encoder_weights='imagenet', classes=len(dataset.classes)+1, activation=activation)\n",
    "\n",
    "# compile keras model with defined optimizer, loss and metrics\n",
    "model.compile(opt, total_loss, metrics=metrics)\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SET_SIZE = 200\n",
    "cnt = 1\n",
    "\n",
    "epochs_size = 10\n",
    "initial_epoch = 0\n",
    "batch_size = 16\n",
    "\n",
    "# goal = 100\n",
    "goal = len(dataset)\n",
    "for i in range(0, goal, SET_SIZE):\n",
    "\tx_train, y_train, x_val, y_val = dataset.export_split(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tdataset.images_fps[i:i+SET_SIZE], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tdataset.masks_fps[i:i+SET_SIZE], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tratio=0.5,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tcat=True)\n",
    "\n",
    "\tpre_x_train = preprocess_input(x_train)\n",
    "\tpre_x_val = preprocess_input(x_val)\n",
    "\n",
    "\thistory = model.fit(pre_x_train, \n",
    "\t\t\ty_train,\n",
    "\t\t\tvalidation_data=(pre_x_val, y_val),\n",
    "\t\t\tbatch_size=batch_size,\n",
    "\t\t\tshuffle=True,\n",
    "\t\t\tverbose=1,\n",
    "\t\t\tinitial_epoch=initial_epoch,\n",
    "\t\t\tepochs=initial_epoch + epochs_size,\n",
    "\t\t\tcallbacks=[checkpoint, tensorboard]\n",
    "\t\t\t)\n",
    "\tmodel.save(f'./models/Linknet/resnet34/latest_after_{initial_epoch + epochs_size}_epochs.keras')\n",
    "\tcnt += 1\n",
    "\tinitial_epoch += epochs_size\n",
    "    \n",
    "# goal = 100\n",
    "goal = len(dataset2)\n",
    "for i in range(0, goal, SET_SIZE):\n",
    "\tx_train, y_train, x_val, y_val = dataset2.export_split(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tdataset2.images_fps[i:i+SET_SIZE], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tdataset2.masks_fps[i:i+SET_SIZE], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tratio=0.5,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tcat=True)\n",
    "\n",
    "\n",
    "\tpre_x_train = preprocess_input(x_train)\n",
    "\tpre_x_val = preprocess_input(x_val)\n",
    "\n",
    "\thistory = model.fit(pre_x_train, \n",
    "\t\t\ty_train,\n",
    "\t\t\tvalidation_data=(pre_x_val, y_val),\n",
    "\t\t\tbatch_size=batch_size,\n",
    "\t\t\tshuffle=True,\n",
    "\t\t\tverbose=1,\n",
    "\t\t\tinitial_epoch=initial_epoch,\n",
    "\t\t\tepochs=initial_epoch + epochs_size,\n",
    "\t\t\tcallbacks=[checkpoint, tensorboard]\n",
    "\t\t\t)\n",
    "\n",
    "\tmodel.save(f'./models/Linknet/resnet34/latest_after_{initial_epoch + epochs_size}_epochs.keras')\n",
    "\tinitial_epoch += epochs_size\n",
    "\tcnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('./models/Linknet/resnet34/latest_after_160_epochs.keras', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test, x_tmp, y_tmp = dataset.export_split(dataset.images_test_fps, dataset.masks_test_fps, 1, cat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_x_test = preprocess_input(x_test)\n",
    "y_pred = model.predict(pre_x_test)\n",
    "y_pred_argmax = np.argmax(y_pred, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred_argmax.shape)\n",
    "np.unique(y_pred_argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import MeanIoU\n",
    "\n",
    "IOU_keras = MeanIoU(num_classes=len(dataset.classes)+1)  \n",
    "IOU_keras.update_state(y_test, y_pred_argmax)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_to_rgb(x):\n",
    "    x_reshaped = np.concatenate([x] * 3, axis=-1)\n",
    "    color_map = {\n",
    "            1: [255, 0, 0],   # Red for lepidic\n",
    "            2: [0, 255, 0],   # Green for acinar\n",
    "            3: [0, 0, 255],    # Blue for micropapillary\n",
    "            4: [255, 255, 0],  # Yellow for papillary\n",
    "            5: [255, 0, 255],   # violet for solid\n",
    "        }\n",
    "    \n",
    "    rgb = np.zeros_like(x_reshaped, dtype=np.uint8)\n",
    "    for label, color in color_map.items():\n",
    "            rgb[x_reshaped[..., 0] == label] = color \n",
    "    return rgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to colors according to classes\n",
    "y_test_show_rgb = gray_to_rgb(y_test)\n",
    "\n",
    "y_pred_argmax = np.expand_dims(y_pred_argmax, axis=-1)\n",
    "y_pred_argmax_show_rgb = gray_to_rgb(y_pred_argmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = randint(0, len(x_test)-1)\n",
    "# idx = 16\n",
    "print(y_test.shape)\n",
    "print(\"y_test unique: \", np.unique(y_test[idx]))\n",
    "print(\"y_pred_argmax unique: \", np.unique(y_pred_argmax[idx]))\n",
    "\n",
    "for idx in range(0, len(x_test)-1):\n",
    "\n",
    "\n",
    "    visualize(\n",
    "        image=x_test[idx],\n",
    "        ground_truth=y_test_show_rgb[idx],\n",
    "        predict=y_pred_argmax_show_rgb[idx]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
