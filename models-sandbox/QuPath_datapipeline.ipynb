{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import albumentations as A\n",
    "from tifffile import imread\n",
    "import segmentation_models as sm\n",
    "from random import randint\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            images_dir, \n",
    "            masks_dir, \n",
    "            classes=None, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "            \n",
    "    ):\n",
    "        self.classes = classes\n",
    "        self.ids = os.listdir(images_dir)\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids] # images file paths\n",
    "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids] # masks file paths\n",
    "\n",
    "        # convert str names to class values on masks\n",
    "        self.class_values = [classes.index(cls.lower()) for cls in classes]\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "\n",
    "    def merge(self, x):\n",
    "        dim = (x.shape[-2], x.shape[-1])\n",
    "        merged = np.zeros(dim)\n",
    "        for i in range(len(self.classes)):\n",
    "            merged = np.where(merged==0, x[i], merged)\n",
    "\n",
    "        merged  = merged.reshape(dim[0], dim[1], 1)\n",
    "\n",
    "        return merged\n",
    "\n",
    "\n",
    "    def to_index(self, x):\n",
    "        for c in range(len(self.classes)):\n",
    "            x[c][x[c] == 255] = c + 1\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "    def export(self, test_ratio = 0.4):\n",
    "        \n",
    "        test_size = int(len(self.images_fps) * test_ratio)\n",
    "        train_size = int( (len(self.images_fps) - test_size) * 0.5 )\n",
    "\n",
    "        images = []\n",
    "        for image_uri in self.images_fps:\n",
    "            img = np.asarray(imread(image_uri), dtype=np.uint8)\n",
    "            images.append(img)\n",
    "        \n",
    "        images = np.asarray(images)\n",
    "\n",
    "        masks = []\n",
    "        for mask_uri in self.masks_fps:\n",
    "            mask = np.asarray(imread(mask_uri), dtype=np.uint8)\n",
    "            mask = self.to_index(mask)\n",
    "            mask = self.merge(mask)\n",
    "            masks.append(mask)\n",
    "        \n",
    "        masks = np.asarray(masks)\n",
    "\n",
    "        print(images.shape, masks.shape)\n",
    "\n",
    "        x_test = images[:test_size]\n",
    "        y_test = masks[:test_size]\n",
    "\n",
    "        masks = to_categorical(masks, num_classes=len(self.classes) + 1)\n",
    "\n",
    "        x_train = images[test_size:test_size+train_size]\n",
    "        y_train = masks[test_size:test_size+train_size]\n",
    "\n",
    "        x_val = images[test_size+train_size:]\n",
    "        y_val = masks[test_size+train_size:]\n",
    "\n",
    "        return x_test, y_test, x_train, y_train, x_val, y_val\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = np.asarray(imread(self.images_fps[i]), dtype=np.uint8)\n",
    "        mask = np.asarray(imread(self.masks_fps[i]), dtype=np.uint8)\n",
    "\n",
    "        print(np.unique(mask))\n",
    "        mask = self.to_index(mask)\n",
    "        mask = self.merge(mask)\n",
    "\n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_uri = r'D:\\NSC2024\\QuPath_proj\\export'\n",
    "\n",
    "dataset = Dataset(\n",
    "    images_dir = os.path.join(export_uri, 'images'),\n",
    "    masks_dir = os.path.join(export_uri, 'masks'),\n",
    "    classes = ['lepidic', 'acinar', 'solid', 'micropapillary', 'papillary'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = randint(0, len(dataset) - 1)\n",
    "image, masks = dataset[r]\n",
    "print(np.unique(masks))\n",
    "print(masks.shape)\n",
    "visualize(\n",
    "    image=image,\n",
    "    mask=masks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test, x_train, y_train, x_val, y_val = dataset.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(y_test))\n",
    "print(np.unique(y_train))\n",
    "print(np.unique(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "activation='softmax'\n",
    "LR = 0.0001\n",
    "opt = keras.optimizers.Adam(LR)\n",
    "\n",
    "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
    "# set class weights for dice_loss (car: 1.; pedestrian: 2.; background: 0.5;)\n",
    "dice_loss = sm.losses.DiceLoss(class_weights=np.array([0, 0.20, 0.20, 0.20, 0.20, 0.20])) \n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "\n",
    "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
    "# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'resnet101'\n",
    "\n",
    "# define model\n",
    "model = sm.Unet(BACKBONE, encoder_weights='imagenet', classes=len(dataset.classes)+1, activation=activation)\n",
    "\n",
    "# compile keras model with defined optimizer, loss and metrics\n",
    "model.compile(opt, total_loss, metrics=metrics)\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "pre_x_train = preprocess_input(x_train)\n",
    "pre_x_val = preprocess_input(x_val)\n",
    "\n",
    "history = model.fit(pre_x_train, \n",
    "          y_train,\n",
    "          validation_data=(pre_x_val, y_val),\n",
    "          batch_size=8, \n",
    "          verbose=2,\n",
    "          epochs=20\n",
    "          )\n",
    "\n",
    "model.save('test.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('./test.keras', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_x_test = preprocess_input(x_test)\n",
    "y_pred = model.predict(pre_x_test)\n",
    "y_pred_argmax = np.argmax(y_pred, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred_argmax.shape)\n",
    "np.unique(y_pred_argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import MeanIoU\n",
    "\n",
    "IOU_keras = MeanIoU(num_classes=len(dataset.classes)+1)  \n",
    "IOU_keras.update_state(y_test[:,:,:,0], y_pred_argmax)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_to_rgb(x):\n",
    "    x_reshaped = np.concatenate([x] * 3, axis=-1)\n",
    "    color_map = {\n",
    "            1: [255, 0, 0],   # Red for lepidic\n",
    "            2: [0, 255, 0],   # Green for acinar\n",
    "            3: [0, 0, 255],    # Blue for micropapillary\n",
    "            4: [255, 255, 0],  # Yellow for papillary\n",
    "            5: [255, 0, 255],   # violet for solid\n",
    "        }\n",
    "    \n",
    "    rgb = np.zeros_like(x_reshaped, dtype=np.uint8)\n",
    "    for label, color in color_map.items():\n",
    "            rgb[x_reshaped[..., 0] == label] = color \n",
    "    return rgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to colors according to classes\n",
    "y_test_show_rgb = gray_to_rgb(y_test)\n",
    "\n",
    "y_pred_argmax = np.expand_dims(y_pred_argmax, axis=-1)\n",
    "y_pred_argmax_show_rgb = gray_to_rgb(y_pred_argmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = randint(0, len(x_test)-1)\n",
    "# idx = 19\n",
    "print(y_test.shape)\n",
    "print(np.unique(y_pred_argmax[idx]))\n",
    "print(\"Index: \", idx)\n",
    "\n",
    "visualize(\n",
    "    image=x_test[idx],\n",
    "    ground_truth=y_test_show_rgb[idx],\n",
    "    predict=y_pred_argmax_show_rgb[idx]\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
