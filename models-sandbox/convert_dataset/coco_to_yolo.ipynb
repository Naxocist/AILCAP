{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://youtu.be/NYeJvxe5nYw\n",
    "\"\"\"\n",
    "This code transforms a dataset of images and annotations into a format suitable \n",
    "for training a YOLO (You Only Look Once) object detection model, and it also \n",
    "creates a YAML configuration file required for training the model.\n",
    "\n",
    "It reads coco style json annotations supplied as a single json file and also \n",
    "images as input. \n",
    "\n",
    "Here are the key steps in the code:\n",
    "\n",
    "1. Convert Images to YOLO Format: The convert_to_yolo function takes paths for \n",
    "input images and annotations (in JSON format), and directories to store the \n",
    "output images and labels. It then performs the following operations:\n",
    "\n",
    "- Reads the input JSON file containing annotations.\n",
    "- Copies all PNG images from the input directory to the output directory.\n",
    "- Normalizes the polygon segmentation data related to each image and writes \n",
    "them to text files, mapping them to the appropriate category \n",
    "(e.g., Alpha, Cells, Mito, Vessels).\n",
    "- The resulting text files contain information about the object category and the normalized coordinates of the polygons that describe the objects.\n",
    "\n",
    "2. Create YAML Configuration File: The create_yaml function takes paths to the input JSON file containing categories, training, validation, and optional test paths. It then:\n",
    "\n",
    "- Extracts the category names and the number of classes.\n",
    "- Constructs a dictionary containing information about class names, the number \n",
    "of classes, and paths to the training, validation, and test datasets.\n",
    "- Writes this dictionary to a YAML file, which can be used as a configuration \n",
    "file for training a model (e.g., a YOLO model).\n",
    "    \n",
    "\n",
    "\n",
    "The text annotation file consists of lines representing individual object \n",
    "annotations, with each line containing the class ID followed by the normalized \n",
    "coordinates of the polygon describing the object.\n",
    "\n",
    "Example structure of the YOLO annotation file:\n",
    "\n",
    "<class_id> <normalized_polygon_coordinate_1> <normalized_polygon_coordinate_2> ... <normalized_polygon_coordinate_n>\n",
    "0 0.123456 0.234567 0.345678 0.456789 ...\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert images to YOLO format\n",
    "def convert_to_yolo(input_images_path, input_json_path, output_images_path, output_labels_path):\n",
    "    # Open JSON file containing image annotations\n",
    "    f = open(input_json_path)\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    # Create directories for output images and labels\n",
    "    os.makedirs(output_images_path, exist_ok=True)\n",
    "    os.makedirs(output_labels_path, exist_ok=True)\n",
    "\n",
    "    # List to store filenames\n",
    "    file_names = []\n",
    "    for filename in os.listdir(input_images_path):\n",
    "        if filename.endswith(\".png\"):\n",
    "            source = os.path.join(input_images_path, filename)\n",
    "            destination = os.path.join(output_images_path, filename)\n",
    "            shutil.copy(source, destination)\n",
    "            file_names.append(filename)\n",
    "\n",
    "    # Function to get image annotations\n",
    "    def get_img_ann(image_id):\n",
    "        return [ann for ann in data['annotations'] if ann['image_id'] == image_id]\n",
    "\n",
    "    # Function to get image data\n",
    "    def get_img(filename):\n",
    "        return next((img for img in data['images'] if img['file_name'] == filename), None)\n",
    "\n",
    "    # Iterate through filenames and process each image\n",
    "    for filename in file_names:\n",
    "        img = get_img(filename)\n",
    "        img_id = img['id']\n",
    "        img_w = img['width']\n",
    "        img_h = img['height']\n",
    "        img_ann = get_img_ann(img_id)\n",
    "\n",
    "        # Write normalized polygon data to a text file\n",
    "        if img_ann:\n",
    "            with open(os.path.join(output_labels_path, f\"{os.path.splitext(filename)[0]}.txt\"), \"a\") as file_object:\n",
    "                for ann in img_ann:\n",
    "                    current_category = ann['category_id'] - 1\n",
    "                    polygon = ann['segmentation'][0]\n",
    "                    normalized_polygon = [format(coord / img_w if i % 2 == 0 else coord / img_h, '.6f') for i, coord in enumerate(polygon)]\n",
    "                    file_object.write(f\"{current_category} \" + \" \".join(normalized_polygon) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a YAML file for the dataset\n",
    "def create_yaml(input_json_path, output_yaml_path, train_path, val_path, test_path=None):\n",
    "    with open(input_json_path) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Extract the category names\n",
    "    names = [category['name'] for category in data['categories']]\n",
    "    \n",
    "    # Number of classes\n",
    "    nc = len(names)\n",
    "\n",
    "    # Create a dictionary with the required content\n",
    "    yaml_data = {\n",
    "        'names': names,\n",
    "        'nc': nc,\n",
    "        'test': test_path if test_path else '',\n",
    "        'train': train_path,\n",
    "        'val': val_path\n",
    "    }\n",
    "\n",
    "    # Write the dictionary to a YAML file\n",
    "    with open(output_yaml_path, 'w') as file:\n",
    "        yaml.dump(yaml_data, file, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    base_input_path = \"EM-platelet-multi/input/\"\n",
    "    base_output_path = \"EM-platelet-multi/yolo_dataset/\"\n",
    "\n",
    "    # Processing validation dataset (if needed)\n",
    "    convert_to_yolo(\n",
    "        input_images_path=os.path.join(base_input_path, \"val_images\"),\n",
    "        input_json_path=os.path.join(base_input_path, \"val_images/val.json\"),\n",
    "        output_images_path=os.path.join(base_output_path, \"valid/images\"),\n",
    "        output_labels_path=os.path.join(base_output_path, \"valid/labels\")\n",
    "    )\n",
    "\n",
    "    # Processing training dataset \n",
    "    convert_to_yolo(\n",
    "        input_images_path=os.path.join(base_input_path, \"train_images\"),\n",
    "        input_json_path=os.path.join(base_input_path, \"train_images/train.json\"),\n",
    "        output_images_path=os.path.join(base_output_path, \"train/images\"),\n",
    "        output_labels_path=os.path.join(base_output_path, \"train/labels\")\n",
    "    )\n",
    "    \n",
    "    # Creating the YAML configuration file\n",
    "    create_yaml(\n",
    "        input_json_path=os.path.join(base_input_path, \"train_images/train.json\"),\n",
    "        output_yaml_path=os.path.join(base_output_path, \"data.yaml\"),\n",
    "        train_path=\"EM-Platelet/train/images\",\n",
    "        val_path=\"EM-Platelet/valid/images\",\n",
    "        test_path='../test/images'  # or None if not applicable\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
