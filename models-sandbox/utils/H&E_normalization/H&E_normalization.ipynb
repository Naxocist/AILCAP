{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "__author__ = \"Sreenivas Bhattiprolu\"\n",
    "__license__ = \"Feel free to copy, I appreciate if you acknowledge Python for Microscopists\"\n",
    "\n",
    "\n",
    "# https://youtu.be/yUrwEYgZUsA\n",
    "\"\"\"\n",
    "This code normalizes staining appearance of H&E stained images.\n",
    "It also separates the hematoxylin and eosing stains in to different images. \n",
    "\n",
    "Workflow based on the following papers:\n",
    "A method for normalizing histology slides for quantitative analysis. \n",
    "M. Macenko et al., ISBI 2009\n",
    "    http://wwwx.cs.unc.edu/~mn/sites/default/files/macenko2009.pdf\n",
    "\n",
    "Efficient nucleus detector in histopathology images. J.P. Vink et al., J Microscopy, 2013\n",
    "\n",
    "Original MATLAB code:\n",
    "    https://github.com/mitkovetta/staining-normalization/blob/master/normalizeStaining.m\n",
    " \n",
    "Other useful references:\n",
    "    https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5226799/\n",
    "    https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0169875\n",
    "\n",
    "PROPOSED WORKFLOW:  \n",
    "    \n",
    "Input: RGB image\n",
    "Step 1: Convert RGB to OD\n",
    "Step 2: Remove data with OD intensity less than β\n",
    "Step 3: Calculate  singular value decomposition (SVD) on the OD tuples\n",
    "Step 4: Create plane from the SVD directions corresponding to the\n",
    "two largest singular values\n",
    "Step 5: Project data onto the plane, and normalize to unit length\n",
    "Step 6: Calculate angle of each point wrt the first SVD direction\n",
    "Step 7: Find robust extremes (αth and (100−α)th 7 percentiles) of the\n",
    "angle\n",
    "Step 8: Convert extreme values back to OD space\n",
    "\n",
    "Output: Optimal Stain Vectors\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### INPUT RGB IMAGE #######################\n",
    "#Using opencv to read images may bemore robust compared to using skimage\n",
    "#but need to remember to convert BGR to RGB.\n",
    "#Also, convert to float later on and normalize to between 0 and 1.\n",
    "\n",
    "#Image downloaded from:\n",
    "#https://pbs.twimg.com/media/C1MkrgQWQAASbdz.jpg\n",
    "img=cv2.imread('./HnE_Image.png', 1)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "Io = 240 # Transmitted light intensity, Normalizing factor for image intensities\n",
    "alpha = 1  #As recommend in the paper. tolerance for the pseudo-min and pseudo-max (default: 1)\n",
    "beta = 0.15 #As recommended in the paper. OD threshold for transparent pixels (default: 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom mpl_toolkits.mplot3d import Axes3D\\n\\nfig = plt.figure(figsize=(16, 8))\\nax1 = fig.add_subplot(121, projection='3d')\\nax1.scatter(img[:,0],img[:,1],img[:,2])\\nax2 = fig.add_subplot(122, projection='3d')\\nax2.scatter(OD[:,0],OD[:,1],OD[:,2])\\n\\nplt.show()\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### Step 1: Convert RGB to OD ###################\n",
    "## reference H&E OD matrix.\n",
    "#Can be updated if you know the best values for your image. \n",
    "#Otherwise use the following default values. \n",
    "#Read the above referenced papers on this topic. \n",
    "HERef = np.array([[0.5626, 0.2159],\n",
    "                  [0.7201, 0.8012],\n",
    "                  [0.4062, 0.5581]])\n",
    "### reference maximum stain concentrations for H&E\n",
    "maxCRef = np.array([1.9705, 1.0308])\n",
    "\n",
    "\n",
    "# extract the height, width and num of channels of image\n",
    "h, w, c = img.shape\n",
    "\n",
    "# reshape image to multiple rows and 3 columns.\n",
    "#Num of rows depends on the image size (wxh)\n",
    "img = img.reshape((-1,3))\n",
    "\n",
    "# calculate optical density\n",
    "# OD = −log10(I)  \n",
    "#OD = -np.log10(img+0.004)  #Use this when reading images with skimage\n",
    "#Adding 0.004 just to avoid log of zero. \n",
    "\n",
    "OD = -np.log10((img.astype(float)+1)/Io) #Use this for opencv imread\n",
    "#Add 1 in case any pixels in the image have a value of 0 (log 0 is indeterminate)\n",
    "\n",
    "\"\"\"\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax1.scatter(img[:,0],img[:,1],img[:,2])\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "ax2.scatter(OD[:,0],OD[:,1],OD[:,2])\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Step 2: Remove data with OD intensity less than β ############\n",
    "# remove transparent pixels (clear region with no tissue)\n",
    "ODhat = OD[~np.any(OD < beta, axis=1)] #Returns an array where OD values are above beta\n",
    "#Check by printing ODhat.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Step 3: Calculate SVD on the OD tuples ######################\n",
    "#Estimate covariance matrix of ODhat (transposed)\n",
    "# and then compute eigen values & eigenvectors.\n",
    "eigvals, eigvecs = np.linalg.eigh(np.cov(ODhat.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Step 4: Create plane from the SVD directions with two largest values ######\n",
    "#project on the plane spanned by the eigenvectors corresponding to the two \n",
    "# largest eigenvalues    \n",
    "That = ODhat.dot(eigvecs[:,1:3]) #Dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Step 5: Project data onto the plane, and normalize to unit length ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Step 6: Calculate angle of each point wrt the first SVD direction ########\n",
    "#find the min and max vectors and project back to OD space\n",
    "phi = np.arctan2(That[:,1],That[:,0])\n",
    "\n",
    "minPhi = np.percentile(phi, alpha)\n",
    "maxPhi = np.percentile(phi, 100-alpha)\n",
    "\n",
    "vMin = eigvecs[:,1:3].dot(np.array([(np.cos(minPhi), np.sin(minPhi))]).T)\n",
    "vMax = eigvecs[:,1:3].dot(np.array([(np.cos(maxPhi), np.sin(maxPhi))]).T)\n",
    "\n",
    "\n",
    "# a heuristic to make the vector corresponding to hematoxylin first and the \n",
    "# one corresponding to eosin second\n",
    "if vMin[0] > vMax[0]:    \n",
    "    HE = np.array((vMin[:,0], vMax[:,0])).T\n",
    "    \n",
    "else:\n",
    "    HE = np.array((vMax[:,0], vMin[:,0])).T\n",
    "\n",
    "\n",
    "# rows correspond to channels (RGB), columns to OD values\n",
    "Y = np.reshape(OD, (-1, 3)).T\n",
    "\n",
    "# determine concentrations of the individual stains\n",
    "C = np.linalg.lstsq(HE,Y, rcond=None)[0]\n",
    "\n",
    "# normalize stain concentrations\n",
    "maxC = np.array([np.percentile(C[0,:], 99), np.percentile(C[1,:],99)])\n",
    "tmp = np.divide(maxC,maxCRef)\n",
    "C2 = np.divide(C,tmp[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Step 8: Convert extreme values back to OD space\n",
    "# recreate the normalized image using reference mixing matrix \n",
    "\n",
    "Inorm = np.multiply(Io, np.exp(-HERef.dot(C2)))\n",
    "Inorm[Inorm>255] = 254\n",
    "Inorm = np.reshape(Inorm.T, (h, w, 3)).astype(np.uint8)  \n",
    "\n",
    "# Separating H and E components\n",
    "\n",
    "H = np.multiply(Io, np.exp(np.expand_dims(-HERef[:,0], axis=1).dot(np.expand_dims(C2[0,:], axis=0))))\n",
    "H[H>255] = 254\n",
    "H = np.reshape(H.T, (h, w, 3)).astype(np.uint8)\n",
    "\n",
    "E = np.multiply(Io, np.exp(np.expand_dims(-HERef[:,1], axis=1).dot(np.expand_dims(C2[1,:], axis=0))))\n",
    "E[E>255] = 254\n",
    "E = np.reshape(E.T, (h, w, 3)).astype(np.uint8)\n",
    "\n",
    "plt.imsave(\"output/HnE_normalized.jpg\", Inorm)\n",
    "plt.imsave(\"output/HnE_separated_H.jpg\", H)\n",
    "plt.imsave(\"output/HnE_separated_E.jpg\", E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
